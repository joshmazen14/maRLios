{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import gym\n",
    "import gym_super_mario_bros\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from gym_super_mario_bros import SuperMarioBrosEnv\n",
    "from tqdm import tqdm\n",
    "import pickle \n",
    "import gym\n",
    "import numpy as np\n",
    "import collections \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "from toolkit.gym_env import *\n",
    "from toolkit.action_utils import *\n",
    "from toolkit.marlios_model import *\n",
    "from toolkit.train_marlios import *\n",
    "from toolkit.constants import *\n",
    "from toolkit.train_test_samples import *\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:cuvj1v4x) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605a117beb3f4f2db3b56664e46b54b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.011 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.082992…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>▃▂▁▁▃▂▂▂▄▄▄▃▃▅▄▇▆▅▅▆▆▆▆▇▇▇█▇▆█▇▇█▇▆▇▆▆▇▆</td></tr><tr><td>avg_std_dev</td><td>▇█▅▄▂▂▂▂▂▁▁▁▂▃▃▂▃▃▃▃▃▃▃▄▄▄▃▄▅▅▅▆▇▇▇▇████</td></tr><tr><td>avg_total_rewards</td><td>█▄▄▅▄▅▄▄▄▄▄▄▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>current exploration</td><td>███▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>current lr</td><td>███▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>flag acquired</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_time_per_ep</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>time</td><td>▇▁███▁██▂▃█████▂█▃████▂██████▂██████████</td></tr><tr><td>total reward</td><td>█▃▇▆▅▅▆▇▃▅▅▄▁▁▂▅▇▄▂▅▇▅▄▅▆▇▃▁▃▃▃▁▁▁▂▁▃▂▄▁</td></tr><tr><td>x_position</td><td>█▂▇▆▅▄▆▇▂▄▄▄▁▁▂▃▇▂▂▅▇▅▂▅▆▇▃▁▃▂▃▁▁▁▂▁▂▂▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>2.90578</td></tr><tr><td>avg_std_dev</td><td>175.49547</td></tr><tr><td>avg_total_rewards</td><td>-3.67</td></tr><tr><td>current exploration</td><td>0.47385</td></tr><tr><td>current lr</td><td>9e-05</td></tr><tr><td>flag acquired</td><td>False</td></tr><tr><td>max_time_per_ep</td><td>200</td></tr><tr><td>time</td><td>200</td></tr><tr><td>total reward</td><td>-204.0</td></tr><tr><td>x_position</td><td>36</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hearty-river-114</strong> at: <a href='https://wandb.ai/marlios/my-awesome-project/runs/cuvj1v4x' target=\"_blank\">https://wandb.ai/marlios/my-awesome-project/runs/cuvj1v4x</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230430_233819-cuvj1v4x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:cuvj1v4x). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/bozhiepokorny/Documents/CSCI566/marlios/maRLios/wandb/run-20230501_001742-7hlsh5ae</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/marlios/my-awesome-project/runs/7hlsh5ae' target=\"_blank\">bumbling-donkey-115</a></strong> to <a href='https://wandb.ai/marlios/my-awesome-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/marlios/my-awesome-project' target=\"_blank\">https://wandb.ai/marlios/my-awesome-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/marlios/my-awesome-project/runs/7hlsh5ae' target=\"_blank\">https://wandb.ai/marlios/my-awesome-project/runs/7hlsh5ae</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 1866/10000 [11:06:58<48:27:24, 21.45s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(\n\u001b[1;32m      2\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m2_conv_layer_batch2d_all_sequential_batch1d\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m     training_mode\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \n\u001b[1;32m      4\u001b[0m     pretrained\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \u001b[39m# use the pretrained model\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m     ep_per_stat\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, \n\u001b[1;32m      6\u001b[0m     gamma\u001b[39m=\u001b[39;49m\u001b[39m0.9\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m     num_episodes\u001b[39m=\u001b[39;49m\u001b[39m10000\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m     lr\u001b[39m=\u001b[39;49m\u001b[39m1e-5\u001b[39;49m, \n\u001b[1;32m      9\u001b[0m     lr_decay\u001b[39m=\u001b[39;49m \u001b[39m0.999\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m     exploration_min\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m     exploration_max \u001b[39m=\u001b[39;49m \u001b[39m1.0\u001b[39;49m, \u001b[39m# setting this to the min for the rerun model\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m     exploration_decay\u001b[39m=\u001b[39;49m\u001b[39m0.995\u001b[39;49m, \n\u001b[1;32m     13\u001b[0m     action_space\u001b[39m=\u001b[39;49mTRAIN_SET,\n\u001b[1;32m     14\u001b[0m     n_actions\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m     15\u001b[0m     debug\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     16\u001b[0m     device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmps\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     17\u001b[0m     max_time_per_ep\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m \u001b[39m# limit runs to 200 seconds\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/CSCI566/marlios/maRLios/toolkit/train_marlios.py:201\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(training_mode, pretrained, lr, gamma, exploration_decay, exploration_min, ep_per_stat, exploration_max, lr_decay, mario_env, action_space, num_episodes, run_id, n_actions, debug, name, max_time_per_ep, device)\u001b[0m\n\u001b[1;32m    198\u001b[0m time_taken \u001b[39m=\u001b[39m time_total \u001b[39m-\u001b[39m info[\u001b[39m\"\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    200\u001b[0m agent\u001b[39m.\u001b[39mremember(state, two_actions_index, reward, state_next, terminal)\n\u001b[0;32m--> 201\u001b[0m loss \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mexperience_replay(debug\u001b[39m=\u001b[39;49mdebug)\n\u001b[1;32m    203\u001b[0m \u001b[39mif\u001b[39;00m loss \u001b[39m!=\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     \u001b[39m# agent.decay_exploration()\u001b[39;00m\n\u001b[1;32m    205\u001b[0m     avg_loss_replay \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(loss)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mitem(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/CSCI566/marlios/maRLios/toolkit/marlios_model.py:258\u001b[0m, in \u001b[0;36mexperience_replay\u001b[0;34m(self, debug)\u001b[0m\n\u001b[1;32m    251\u001b[0m target \u001b[39m=\u001b[39m REWARD \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39mmul((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma \u001b[39m*\u001b[39m \n\u001b[1;32m    252\u001b[0m                             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_net(STATE2, SPACE)\u001b[39m.\u001b[39mmax(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)), \n\u001b[1;32m    253\u001b[0m                             \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m DONE)\n\u001b[1;32m    255\u001b[0m current \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocal_net(STATE, SPACE)\u001b[39m.\u001b[39mgather(\u001b[39m1\u001b[39m, ACTION\u001b[39m.\u001b[39mlong()) \u001b[39m# Local net approximation of Q-value\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ml1(current, target) \u001b[39m# maybe we can play with some L2 loss \u001b[39;00m\n\u001b[1;32m    259\u001b[0m loss\u001b[39m.\u001b[39mbackward() \u001b[39m# Compute gradients\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep() \u001b[39m# Backpropagate error\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/marlios-env/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/marlios-env/lib/python3.10/site-packages/torch/autograd/__init__.py:204\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    201\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    205\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    206\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(\n",
    "    name=\"3_conv_layer_batch2d_all_sequential_batch1d\",\n",
    "    training_mode=True, \n",
    "    pretrained=False, # use the pretrained model\n",
    "    ep_per_stat=100, \n",
    "    gamma=0.9,\n",
    "    num_episodes=10000,\n",
    "    lr=1e-4, \n",
    "    lr_decay= 0.999,\n",
    "    exploration_min=0.2,\n",
    "    exploration_max = 1.0, # setting this to the min for the rerun model\n",
    "    exploration_decay=0.995, \n",
    "    action_space=TRAIN_SET,\n",
    "    n_actions=26,\n",
    "    debug=True,\n",
    "    device='mps',\n",
    "    max_time_per_ep=200 # limit runs to 200 seconds\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only need to run if you cut the above off early, even then you don't 'have' to but it will do it automatically for you, it's just not as nice to have the output above as well\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking out the run on simple movement\n",
    "run_id='1682477759'\n",
    "visualize(run_id=run_id, action_space=SIMPLE_MOVEMENT, n_actions=len(SIMPLE_MOVEMENT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp ModelCheckpoints/*1682283822* . resetting this run here\n",
    "\n",
    "total_rewards = load_item('total_rewards-{}.pkl'.format(run_id))\n",
    "plot_rewards(ep_per_stat=100, total_rewards=total_rewards)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marlios",
   "language": "python",
   "name": "marlios"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
