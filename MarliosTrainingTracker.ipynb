{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import gym\n",
    "import gym_super_mario_bros\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from gym_super_mario_bros import SuperMarioBrosEnv\n",
    "from tqdm import tqdm\n",
    "import pickle \n",
    "import gym\n",
    "import numpy as np\n",
    "import collections \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "from toolkit.gym_env import *\n",
    "from toolkit.action_utils import *\n",
    "from toolkit.marlios_model import *\n",
    "from toolkit.train_marlios import *\n",
    "from toolkit.constants import *\n",
    "from toolkit.train_test_samples import *\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpokorny\u001b[0m (\u001b[33mmarlios\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/bozhiepokorny/Documents/CSCI566/marlios/maRLios/wandb/run-20230430_175958-mrfpuwct</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/marlios/my-awesome-project/runs/mrfpuwct' target=\"_blank\">comic-serenity-102</a></strong> to <a href='https://wandb.ai/marlios/my-awesome-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/marlios/my-awesome-project' target=\"_blank\">https://wandb.ai/marlios/my-awesome-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/marlios/my-awesome-project/runs/mrfpuwct' target=\"_blank\">https://wandb.ai/marlios/my-awesome-project/runs/mrfpuwct</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:23<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "DQNAgent.decay_exploration() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(\n\u001b[1;32m      2\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m3_conv_layer_batch2d_all_sequential_batch1d\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m     training_mode\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \n\u001b[1;32m      4\u001b[0m     pretrained\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \u001b[39m# use the pretrained model\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m     ep_per_stat\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, \n\u001b[1;32m      6\u001b[0m     gamma\u001b[39m=\u001b[39;49m\u001b[39m0.9\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m     num_episodes\u001b[39m=\u001b[39;49m\u001b[39m10000\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m     lr\u001b[39m=\u001b[39;49m\u001b[39m1e-4\u001b[39;49m, \n\u001b[1;32m      9\u001b[0m     lr_decay\u001b[39m=\u001b[39;49m \u001b[39m0.999\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m     exploration_min\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m     exploration_max \u001b[39m=\u001b[39;49m \u001b[39m1.0\u001b[39;49m, \u001b[39m# setting this to the min for the rerun model\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m     exploration_decay\u001b[39m=\u001b[39;49m\u001b[39m0.995\u001b[39;49m, \n\u001b[1;32m     13\u001b[0m     action_space\u001b[39m=\u001b[39;49mTRAIN_SET,\n\u001b[1;32m     14\u001b[0m     n_actions\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m     15\u001b[0m     debug\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     16\u001b[0m     device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmps\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     17\u001b[0m     max_time_per_ep\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m \u001b[39m# limit runs to 200 seconds\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/CSCI566/marlios/maRLios/toolkit/train_marlios.py:254\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(training_mode, pretrained, lr, gamma, exploration_decay, exploration_min, ep_per_stat, exploration_max, lr_decay, mario_env, action_space, num_episodes, run_id, n_actions, debug, name, max_time_per_ep, device)\u001b[0m\n\u001b[1;32m    240\u001b[0m wandb\u001b[39m.\u001b[39mlog({\u001b[39m\"\u001b[39m\u001b[39mtotal reward\u001b[39m\u001b[39m\"\u001b[39m : total_reward, \n\u001b[1;32m    241\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39mcurrent lr\u001b[39m\u001b[39m\"\u001b[39m: agent\u001b[39m.\u001b[39mlr,\n\u001b[1;32m    242\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39mcurrent exploration\u001b[39m\u001b[39m\"\u001b[39m: agent\u001b[39m.\u001b[39mexploration_rate,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39mavg_std_dev\u001b[39m\u001b[39m\"\u001b[39m: avg_stdevs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    250\u001b[0m            })\n\u001b[1;32m    253\u001b[0m \u001b[39m#agent.decay_lr(lr_decay)\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m agent\u001b[39m.\u001b[39;49mdecay_exploration(lr_decay)\n\u001b[1;32m    255\u001b[0m agent\u001b[39m.\u001b[39msubsample_actions()\n\u001b[1;32m    257\u001b[0m \u001b[39m# update the max time per episode every 1000 episodes\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: DQNAgent.decay_exploration() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    name=\"3_conv_layer_batch2d_all_sequential_batch1d\",\n",
    "    training_mode=True, \n",
    "    pretrained=False, # use the pretrained model\n",
    "    ep_per_stat=100, \n",
    "    gamma=0.9,\n",
    "    num_episodes=10000,\n",
    "    lr=1e-4, \n",
    "    lr_decay= 0.999,\n",
    "    exploration_min=0.2,\n",
    "    exploration_max = 1.0, # setting this to the min for the rerun model\n",
    "    exploration_decay=0.995, \n",
    "    action_space=TRAIN_SET,\n",
    "    n_actions=32,\n",
    "    debug=True,\n",
    "    device='mps',\n",
    "    max_time_per_ep=200 # limit runs to 200 seconds\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only need to run if you cut the above off early, even then you don't 'have' to but it will do it automatically for you, it's just not as nice to have the output above as well\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking out the run on simple movement\n",
    "run_id='1682477759'\n",
    "visualize(run_id=run_id, action_space=SIMPLE_MOVEMENT, n_actions=len(SIMPLE_MOVEMENT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp ModelCheckpoints/*1682283822* . resetting this run here\n",
    "\n",
    "total_rewards = load_item('total_rewards-{}.pkl'.format(run_id))\n",
    "plot_rewards(ep_per_stat=100, total_rewards=total_rewards)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marlios",
   "language": "python",
   "name": "marlios"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
