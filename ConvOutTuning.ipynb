{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import gym\n",
    "import gym_super_mario_bros\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from gym_super_mario_bros import SuperMarioBrosEnv\n",
    "from tqdm import tqdm\n",
    "import pickle \n",
    "import gym\n",
    "import numpy as np\n",
    "import collections \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "from toolkit.gym_env import *\n",
    "from toolkit.action_utils import *\n",
    "from toolkit.marlios_model import *\n",
    "from toolkit.constants import *\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_state(env, ep=0, info=\"\"):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"Episode: %d %s\" % (ep, info))\n",
    "    plt.axis('off')\n",
    "\n",
    "    # display.clear_output(wait=True)\n",
    "    # display.display(plt.gcf())\n",
    "    display(plt.gcf(), clear=True)\n",
    "\n",
    "def make_env(env, actions=ACTION_SPACE):\n",
    "    env = MaxAndSkipEnv(env, skip=2) # I am testing out fewer fram repetitions for our two actions modelling\n",
    "    env = ProcessFrame84(env)\n",
    "    env = ImageToPyTorch(env)\n",
    "    env = BufferWrapper(env, 4)\n",
    "    env = ScaledFloatFrame(env)\n",
    "    return JoypadSpace(env, actions)\n",
    "\n",
    "def generate_epoch_time_id():\n",
    "    epoch_time = int(time.time())\n",
    "    return str(epoch_time)\n",
    "\n",
    "def save_checkpoint(agent, total_rewards, terminal_info, run_id):\n",
    "    with open(f\"ending_position-{run_id}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(agent.ending_position, f)\n",
    "    with open(f\"num_in_queue-{run_id}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(agent.num_in_queue, f)\n",
    "    with open(f\"total_rewards-{run_id}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(total_rewards, f)\n",
    "    with open(f\"terminal_info-{run_id}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(terminal_info, f)\n",
    "    if agent.double_dq:\n",
    "        torch.save(agent.local_net.state_dict(), f\"dq1-{run_id}.pt\")\n",
    "        torch.save(agent.target_net.state_dict(), f\"dq2-{run_id}.pt\")\n",
    "    else:\n",
    "        torch.save(agent.dqn.state_dict(), f\"dq-{run_id}.pt\")  \n",
    "\n",
    "def load_rewards(from_file):\n",
    "     with open(from_file, 'rb') as f:\n",
    "        total_rewards = pickle.load(f)\n",
    "        return total_rewards\n",
    "\n",
    "def plot_rewards(ep_per_stat = 100, total_rewards = [], from_file = None):\n",
    "    if from_file != None:\n",
    "        total_rewards = load_rewards(total_rewards)\n",
    "       \n",
    "    avg_rewards = [np.mean(total_rewards[i:i+ep_per_stat]) for i in range(0, len(total_rewards), ep_per_stat)]\n",
    "    std_rewards = [np.std(total_rewards[i:i+ep_per_stat]) for i in range(0, len(total_rewards), ep_per_stat)]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(avg_rewards, label='Average Rewards')\n",
    "    ax.fill_between(range(len(avg_rewards)), np.subtract(avg_rewards, std_rewards), np.add(avg_rewards, std_rewards), alpha=0.2, label='Reward StdDev')\n",
    "\n",
    "    ax.set_xlabel('Episode')\n",
    "    ax.set_ylabel('Reward')\n",
    "    xtick_labels = [str(i*ep_per_stat) for i in range(len(avg_rewards))]\n",
    "    plt.xticks(range(1, len(avg_rewards)+1), xtick_labels)\n",
    "    plt.xticks(rotation=45)\n",
    "    ax.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNSolver(nn.Module):\n",
    "\n",
    "    def __init__(self, input_shape):\n",
    "        super(DQNSolver, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 64, kernel_size=6, stride=2),\n",
    "            nn.MaxPool2d(kernel_size=4, stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(64, 32, kernel_size=4, stride=1),\n",
    "            nn.MaxPool2d(kernel_size=4, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(32, 12, kernel_size=4, stride=1),\n",
    "            nn.BatchNorm2d(12),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        conv_out_size = self._get_conv_out(input_shape)\n",
    "        # takes the output of the convolutions and gets vector to size 32\n",
    "        self.conv_to_32 = nn.Sequential(\n",
    "            nn.Linear(conv_out_size, 32),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "        action_size = 10\n",
    "\n",
    "        self.action_fc = nn.Sequential(\n",
    "            nn.Linear(action_size, 32),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        \n",
    "        # We take a vector of 5 being the initial action, and 5 being the second action for action size of 10\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, 32), # added a new layer can play with the parameters\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    \n",
    "    def _get_conv_out(self, shape):\n",
    "        o = self.conv(torch.zeros(1, *shape))\n",
    "        return int(np.prod(o.size()))\n",
    "\n",
    "    def forward(self, x, sampled_actions):\n",
    "        '''\n",
    "        x - image being passed in as the state\n",
    "        sampled_actions - np.array with n x 8 \n",
    "        '''\n",
    "        big_conv_out = self.conv(x).view(x.size()[0], -1)\n",
    "        conv_out = self.conv_to_32(big_conv_out)\n",
    "\n",
    "        batched_conv_out = conv_out.reshape(conv_out.shape[0], 1, conv_out.shape[-1]).repeat(1, sampled_actions.shape[-2], 1)\n",
    "\n",
    "        latent_actions = self.action_fc(sampled_actions)\n",
    "\n",
    "        batched_actions = torch.cat((batched_conv_out, latent_actions), dim=2)\n",
    "\n",
    "        out =  torch.flatten(self.fc(batched_actions), start_dim=1)\n",
    "\n",
    "        return out\n",
    "\n",
    "mario_env='SuperMarioBros-1-1-v0'\n",
    "env = gym.make(mario_env)\n",
    "env = make_env(env, ACTION_SPACE)\n",
    "\n",
    "\n",
    "# observation_space = env.observation_space.shape # not using this anymore\n",
    "state_space=env.observation_space.shape\n",
    "#todo: add agent params as a setting/create different agents in diff functions to run \n",
    "local_net = DQNSolver(state_space)\n",
    "\n",
    "state = env.reset()\n",
    "state = torch.tensor([state])\n",
    "\n",
    "sampled_actions = torch.from_numpy(sample_actions(TWO_ACTIONS_SET, 10)).to(torch.float32).unsqueeze(0) \n",
    "\n",
    "\n",
    "print(local_net(state, sampled_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_state(env, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = state\n",
    "\n",
    "big_conv_out = local_net.conv(x).view(x.size()[0], -1)\n",
    "conv_out = local_net.conv_to_32(big_conv_out)\n",
    "\n",
    "batched_conv_out = conv_out.reshape(conv_out.shape[0], 1, conv_out.shape[-1]).repeat(1, sampled_actions.shape[-2], 1)\n",
    "\n",
    "latent_actions = local_net.action_fc(sampled_actions)\n",
    "\n",
    "batched_actions = torch.cat((batched_conv_out, latent_actions), dim=2)\n",
    "\n",
    "out =  torch.flatten(local_net.fc(batched_actions), start_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(out).data.numpy().item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to come up with train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(SUFFICIENT_ACTIONS)*0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "action_set = SUFFICIENT_ACTIONS\n",
    "indices = [i for i in range(len(action_set))]\n",
    "n = len(indices)\n",
    "train_indices = random.sample(indices, int(n*0.7)) # 70% train split\n",
    "test_indices = [i for i in indices if i not in train_indices] # keep the remaining in the test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SET\n",
      "\t [['A', 'down', 'right'], ['A', 'down']] ,\n",
      "\t [['A', 'B', 'right'], ['A', 'right']] ,\n",
      "\t [['A', 'down', 'right'], ['A', 'down', 'right']] ,\n",
      "\t [['A', 'right'], ['A', 'B']] ,\n",
      "\t [['A', 'B', 'right'], ['A', 'down', 'right']] ,\n",
      "\t [['A', 'down', 'right'], ['A', 'B', 'right']] ,\n",
      "\t [['A', 'B', 'down', 'right'], ['A', 'B', 'down']] ,\n",
      "\t [['A', 'B', 'down', 'right'], ['A', 'B', 'down', 'right']] ,\n",
      "\t [['A', 'B', 'down', 'right'], ['A', 'right']] ,\n",
      "\t [['A', 'B', 'down', 'right'], ['A']] ,\n",
      "\t [['A'], ['A', 'right']] ,\n",
      "\t [['A', 'right'], ['A', 'B', 'right']] ,\n",
      "\t [['A', 'down', 'right'], ['A', 'right']] ,\n",
      "\t [['A', 'B', 'down'], ['A', 'down', 'right']] ,\n",
      "\t [['A', 'B', 'right'], ['A', 'B', 'right']] ,\n",
      "\t [['A', 'B'], ['A', 'B', 'right']] ,\n",
      "\t [['A', 'down', 'right'], ['A', 'B', 'down', 'right']] ,\n",
      "\t [['A', 'right'], ['A', 'down']] ,\n",
      "\t [['A', 'B'], ['A', 'B', 'down', 'right']] ,\n",
      "\t [['A', 'down', 'right'], ['A']] ,\n",
      "\t [['A', 'B', 'right'], ['A', 'down']] ,\n",
      "\t [['A', 'B', 'down'], ['A', 'B', 'right']] ,\n",
      "\t [['A', 'down', 'right'], ['A', 'B', 'down']] ,\n",
      "\t [['A', 'B', 'right'], ['A', 'B', 'down', 'right']] ,\n",
      "\t [['A', 'B', 'down', 'right'], ['A', 'down', 'right']] ,\n",
      "\t [['A', 'right'], ['A', 'B', 'down']] ,\n",
      "\t [['A', 'down'], ['A', 'right']] ,\n",
      "\t [['A', 'down'], ['A', 'B', 'down', 'right']] ,\n",
      "\t [['A', 'down'], ['A', 'down', 'right']] ,\n",
      "\t [['A', 'right'], ['A', 'B', 'down', 'right']] ,\n",
      "\t [['A'], ['A', 'B', 'right']] ,\n",
      "\t [['A', 'B', 'right'], ['A', 'B']] ,\n",
      "\t [['A', 'right'], ['A', 'right']] ,\n",
      "\n",
      "TEST_SET\n",
      "\t [['A'], ['A', 'B', 'down', 'right']] ,\n",
      "\t [['A'], ['A', 'down', 'right']] ,\n",
      "\t [['A', 'B'], ['A', 'down', 'right']] ,\n",
      "\t [['A', 'B'], ['A', 'right']] ,\n",
      "\t [['A', 'B', 'down'], ['A', 'B', 'down', 'right']] ,\n",
      "\t [['A', 'B', 'down'], ['A', 'right']] ,\n",
      "\t [['A', 'B', 'down', 'right'], ['A', 'B']] ,\n",
      "\t [['A', 'B', 'down', 'right'], ['A', 'B', 'right']] ,\n",
      "\t [['A', 'B', 'down', 'right'], ['A', 'down']] ,\n",
      "\t [['A', 'B', 'right'], ['A']] ,\n",
      "\t [['A', 'B', 'right'], ['A', 'B', 'down']] ,\n",
      "\t [['A', 'down'], ['A', 'B', 'right']] ,\n",
      "\t [['A', 'down', 'right'], ['A', 'B']] ,\n",
      "\t [['A', 'right'], ['A']] ,\n",
      "\t [['A', 'right'], ['A', 'down', 'right']] ,\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN_SET\")\n",
    "for i in train_indices:\n",
    "    print(\"\\t\",action_set[i], \",\")\n",
    "\n",
    "print(\"\\nTEST_SET\")\n",
    "for i in test_indices:\n",
    "    print(\"\\t\",action_set[i], \",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
